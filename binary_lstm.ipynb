{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b3dbc2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "db54fc4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4261.48</td>\n",
       "      <td>4485.39</td>\n",
       "      <td>4200.74</td>\n",
       "      <td>4285.08</td>\n",
       "      <td>795.150377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4285.08</td>\n",
       "      <td>4371.52</td>\n",
       "      <td>3938.77</td>\n",
       "      <td>4108.37</td>\n",
       "      <td>1199.888264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4108.37</td>\n",
       "      <td>4184.69</td>\n",
       "      <td>3850.00</td>\n",
       "      <td>4139.98</td>\n",
       "      <td>381.309763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4120.98</td>\n",
       "      <td>4211.08</td>\n",
       "      <td>4032.62</td>\n",
       "      <td>4086.29</td>\n",
       "      <td>467.083022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4069.13</td>\n",
       "      <td>4119.62</td>\n",
       "      <td>3911.79</td>\n",
       "      <td>4016.00</td>\n",
       "      <td>691.743060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      open     high      low    close       volume\n",
       "0  4261.48  4485.39  4200.74  4285.08   795.150377\n",
       "1  4285.08  4371.52  3938.77  4108.37  1199.888264\n",
       "2  4108.37  4184.69  3850.00  4139.98   381.309763\n",
       "3  4120.98  4211.08  4032.62  4086.29   467.083022\n",
       "4  4069.13  4119.62  3911.79  4016.00   691.743060"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('btc_1d.csv')\n",
    "data.drop(columns='timestamp',inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "30df3bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>target</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4261.48</td>\n",
       "      <td>4485.39</td>\n",
       "      <td>4200.74</td>\n",
       "      <td>4285.08</td>\n",
       "      <td>795.150377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>223.91</td>\n",
       "      <td>84.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4285.08</td>\n",
       "      <td>4371.52</td>\n",
       "      <td>3938.77</td>\n",
       "      <td>4108.37</td>\n",
       "      <td>1199.888264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.44</td>\n",
       "      <td>169.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4108.37</td>\n",
       "      <td>4184.69</td>\n",
       "      <td>3850.00</td>\n",
       "      <td>4139.98</td>\n",
       "      <td>381.309763</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76.32</td>\n",
       "      <td>289.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4120.98</td>\n",
       "      <td>4211.08</td>\n",
       "      <td>4032.62</td>\n",
       "      <td>4086.29</td>\n",
       "      <td>467.083022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.10</td>\n",
       "      <td>53.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4069.13</td>\n",
       "      <td>4119.62</td>\n",
       "      <td>3911.79</td>\n",
       "      <td>4016.00</td>\n",
       "      <td>691.743060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.49</td>\n",
       "      <td>104.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      open     high      low    close       volume  target      f1      f2\n",
       "0  4261.48  4485.39  4200.74  4285.08   795.150377     1.0  223.91   84.34\n",
       "1  4285.08  4371.52  3938.77  4108.37  1199.888264     0.0   86.44  169.60\n",
       "2  4108.37  4184.69  3850.00  4139.98   381.309763     1.0   76.32  289.98\n",
       "3  4120.98  4211.08  4032.62  4086.29   467.083022     0.0   90.10   53.67\n",
       "4  4069.13  4119.62  3911.79  4016.00   691.743060     0.0   50.49  104.21"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'] = (np.sign(data['close']-data['open'])+1)/2\n",
    "data['f1'] = data['high']-data['open']\n",
    "data['f2'] = data['close']-data['low']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a54da27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2566 entries, 0 to 2565\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   open    2566 non-null   float64\n",
      " 1   high    2566 non-null   float64\n",
      " 2   low     2566 non-null   float64\n",
      " 3   close   2566 non-null   float64\n",
      " 4   volume  2566 non-null   float64\n",
      " 5   target  2566 non-null   float64\n",
      " 6   f1      2566 non-null   float64\n",
      " 7   f2      2566 non-null   float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 160.5 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "feb023b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature and target separation\n",
    "X = data.drop(columns=['open','close','target'])\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0ac91ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 [==============================] - 2s 7ms/step - loss: 1.2785 - accuracy: 0.4811\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7597 - accuracy: 0.4900\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7028 - accuracy: 0.5056\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6942 - accuracy: 0.5139\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6896 - accuracy: 0.5223\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6837 - accuracy: 0.5490\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6846 - accuracy: 0.5317\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6809 - accuracy: 0.5496\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6764 - accuracy: 0.5718\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6684 - accuracy: 0.6008\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6620 - accuracy: 0.6130\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6579 - accuracy: 0.6208\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6510 - accuracy: 0.6091\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6491 - accuracy: 0.6269\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6374 - accuracy: 0.6498\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6341 - accuracy: 0.6292\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6324 - accuracy: 0.6492\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6337 - accuracy: 0.6453\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6255 - accuracy: 0.6570\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6314 - accuracy: 0.6626\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6238 - accuracy: 0.6704\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6218 - accuracy: 0.6503\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6341 - accuracy: 0.6682\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6154 - accuracy: 0.6787\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6341 - accuracy: 0.6854\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6129 - accuracy: 0.6810\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6078 - accuracy: 0.6915\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6046 - accuracy: 0.6748\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6038 - accuracy: 0.6971\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5963 - accuracy: 0.6982\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5982 - accuracy: 0.6876\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6208 - accuracy: 0.6854\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5938 - accuracy: 0.7060\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5899 - accuracy: 0.6915\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5892 - accuracy: 0.7094\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5856 - accuracy: 0.7049\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5936 - accuracy: 0.7210\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5758 - accuracy: 0.7077\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5858 - accuracy: 0.7066\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5888 - accuracy: 0.7066\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5849 - accuracy: 0.7300\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5720 - accuracy: 0.7249\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5841 - accuracy: 0.7144\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5757 - accuracy: 0.7255\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5805 - accuracy: 0.7261\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5580 - accuracy: 0.7366\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5688 - accuracy: 0.7355\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5567 - accuracy: 0.7294\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5685 - accuracy: 0.7210\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5713 - accuracy: 0.7344\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5609 - accuracy: 0.7405\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5749 - accuracy: 0.7455\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5556 - accuracy: 0.7461\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5496 - accuracy: 0.7500\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5405 - accuracy: 0.7578\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5411 - accuracy: 0.7389\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5499 - accuracy: 0.7617\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5256 - accuracy: 0.7528\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5383 - accuracy: 0.7628\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5211 - accuracy: 0.7700\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5218 - accuracy: 0.7661\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5259 - accuracy: 0.7455\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5375 - accuracy: 0.7595\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5402 - accuracy: 0.7578\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5298 - accuracy: 0.7661\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5386 - accuracy: 0.7511\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5412 - accuracy: 0.7645\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5255 - accuracy: 0.7667\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5354 - accuracy: 0.7606\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5055 - accuracy: 0.7684\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5036 - accuracy: 0.7745\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4993 - accuracy: 0.7778\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5091 - accuracy: 0.7812\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4983 - accuracy: 0.7773\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5099 - accuracy: 0.7600\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4929 - accuracy: 0.7661\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4951 - accuracy: 0.7801\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4991 - accuracy: 0.7762\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4932 - accuracy: 0.7695\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5123 - accuracy: 0.7845\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4825 - accuracy: 0.7728\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5013 - accuracy: 0.7901\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4892 - accuracy: 0.7856\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4845 - accuracy: 0.7817\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5138 - accuracy: 0.7795\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4906 - accuracy: 0.7778\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.4734 - accuracy: 0.7940\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5017 - accuracy: 0.7856\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4720 - accuracy: 0.7851\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4751 - accuracy: 0.7829\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4758 - accuracy: 0.7756\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4873 - accuracy: 0.7934\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4720 - accuracy: 0.7884\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4640 - accuracy: 0.7873\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4613 - accuracy: 0.8001\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4627 - accuracy: 0.7951\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4731 - accuracy: 0.7912\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4626 - accuracy: 0.8029\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4742 - accuracy: 0.7840\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4539 - accuracy: 0.7979\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.7636\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "# model.add(Dense(units=64,activation='relu',input_shape=(X_train.shape[1],)))\n",
    "model.add(LSTM(64, activation='relu',input_shape=(X_train.shape[1],1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=8,activation='relu'))\n",
    "model.add(Dense(units=1,activation='tanh'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping callback\n",
    "# early_stop = EarlyStopping(monitor='loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=64)#, callbacks=[early_stop])\n",
    "\n",
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(X_test,y_test)\n",
    "# print(f'Classification report is: {classification_report(y_pred,y_test)} \\n')\n",
    "# print(f'Confusion matrix is: {confusion_matrix(y_pred,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a10b6b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "57/57 [==============================] - 4s 7ms/step - loss: 1.3440 - accuracy: 0.4922\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7209 - accuracy: 0.5006\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6755 - accuracy: 0.5685\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6625 - accuracy: 0.6030\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6543 - accuracy: 0.6047\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6398 - accuracy: 0.6192\n",
      "Epoch 7/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6218 - accuracy: 0.6587\n",
      "Epoch 8/100\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.6060 - accuracy: 0.6720\n",
      "Epoch 9/100\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.5838 - accuracy: 0.6932\n",
      "Epoch 10/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5687 - accuracy: 0.7004\n",
      "Epoch 11/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5792 - accuracy: 0.6904\n",
      "Epoch 12/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5504 - accuracy: 0.7144\n",
      "Epoch 13/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5322 - accuracy: 0.7216\n",
      "Epoch 14/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5382 - accuracy: 0.7294\n",
      "Epoch 15/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5135 - accuracy: 0.7467\n",
      "Epoch 16/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5199 - accuracy: 0.7433\n",
      "Epoch 17/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4959 - accuracy: 0.7695\n",
      "Epoch 18/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4901 - accuracy: 0.7550\n",
      "Epoch 19/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5172 - accuracy: 0.7550\n",
      "Epoch 20/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4920 - accuracy: 0.7717\n",
      "Epoch 21/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4682 - accuracy: 0.7906\n",
      "Epoch 22/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4667 - accuracy: 0.7751\n",
      "Epoch 23/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4839 - accuracy: 0.7723\n",
      "Epoch 24/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4610 - accuracy: 0.7834\n",
      "Epoch 25/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4506 - accuracy: 0.7873\n",
      "Epoch 26/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4282 - accuracy: 0.8151\n",
      "Epoch 27/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4452 - accuracy: 0.7867\n",
      "Epoch 28/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4436 - accuracy: 0.7901\n",
      "Epoch 29/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4278 - accuracy: 0.8146\n",
      "Epoch 30/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4187 - accuracy: 0.8112\n",
      "Epoch 31/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4210 - accuracy: 0.8007\n",
      "Epoch 32/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6582 - accuracy: 0.6704\n",
      "Epoch 33/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5045 - accuracy: 0.7567\n",
      "Epoch 34/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4764 - accuracy: 0.7734\n",
      "Epoch 35/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4516 - accuracy: 0.7962\n",
      "Epoch 36/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4462 - accuracy: 0.7973\n",
      "Epoch 37/100\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.4329 - accuracy: 0.8018\n",
      "Epoch 38/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4290 - accuracy: 0.7996\n",
      "Epoch 39/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4214 - accuracy: 0.8107\n",
      "Epoch 40/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4179 - accuracy: 0.8096\n",
      "Epoch 41/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4147 - accuracy: 0.8046\n",
      "Epoch 42/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4066 - accuracy: 0.8224\n",
      "Epoch 43/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4223 - accuracy: 0.8112\n",
      "Epoch 44/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4092 - accuracy: 0.8229\n",
      "Epoch 45/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7004 - accuracy: 0.6960\n",
      "Epoch 46/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5550 - accuracy: 0.7082\n",
      "Epoch 47/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.5259 - accuracy: 0.7350\n",
      "Epoch 48/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4926 - accuracy: 0.7667\n",
      "Epoch 49/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4790 - accuracy: 0.7790\n",
      "Epoch 50/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4575 - accuracy: 0.7851\n",
      "Epoch 51/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4598 - accuracy: 0.7929\n",
      "Epoch 52/100\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.4479 - accuracy: 0.7890\n",
      "Epoch 53/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4277 - accuracy: 0.8135\n",
      "Epoch 54/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4210 - accuracy: 0.8046\n",
      "Epoch 55/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4174 - accuracy: 0.8051\n",
      "Epoch 56/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4140 - accuracy: 0.8129\n",
      "Epoch 57/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4169 - accuracy: 0.7940\n",
      "Epoch 58/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4016 - accuracy: 0.8179\n",
      "Epoch 59/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3960 - accuracy: 0.8174\n",
      "Epoch 60/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8124\n",
      "Epoch 61/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3973 - accuracy: 0.8163\n",
      "Epoch 62/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3970 - accuracy: 0.8246\n",
      "Epoch 63/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3969 - accuracy: 0.8135\n",
      "Epoch 64/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3917 - accuracy: 0.8190\n",
      "Epoch 65/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3907 - accuracy: 0.8285\n",
      "Epoch 66/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3905 - accuracy: 0.8241\n",
      "Epoch 67/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3926 - accuracy: 0.8218\n",
      "Epoch 68/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3857 - accuracy: 0.8268\n",
      "Epoch 69/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3965 - accuracy: 0.8146\n",
      "Epoch 70/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3776 - accuracy: 0.8369\n",
      "Epoch 71/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3775 - accuracy: 0.8313\n",
      "Epoch 72/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3894 - accuracy: 0.8246\n",
      "Epoch 73/100\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3720 - accuracy: 0.8291\n",
      "Epoch 74/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3913 - accuracy: 0.8196\n",
      "Epoch 75/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3928 - accuracy: 0.8274\n",
      "Epoch 76/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3841 - accuracy: 0.8318\n",
      "Epoch 77/100\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3875 - accuracy: 0.8268\n",
      "Epoch 78/100\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3958 - accuracy: 0.8218\n",
      "Epoch 79/100\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3771 - accuracy: 0.8335\n",
      "Epoch 80/100\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3788 - accuracy: 0.8291\n",
      "Epoch 81/100\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3715 - accuracy: 0.8257\n",
      "Epoch 82/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3679 - accuracy: 0.8330\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3780 - accuracy: 0.8313\n",
      "Epoch 84/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3688 - accuracy: 0.8274\n",
      "Epoch 85/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3667 - accuracy: 0.8313\n",
      "Epoch 86/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3679 - accuracy: 0.8335\n",
      "Epoch 87/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3637 - accuracy: 0.8447\n",
      "Epoch 88/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3522 - accuracy: 0.8452\n",
      "Epoch 89/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3568 - accuracy: 0.8363\n",
      "Epoch 90/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3739 - accuracy: 0.8302\n",
      "Epoch 91/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3657 - accuracy: 0.8447\n",
      "Epoch 92/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3620 - accuracy: 0.8341\n",
      "Epoch 93/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3652 - accuracy: 0.8274\n",
      "Epoch 94/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3575 - accuracy: 0.8385\n",
      "Epoch 95/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3646 - accuracy: 0.8346\n",
      "Epoch 96/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3545 - accuracy: 0.8447\n",
      "Epoch 97/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3516 - accuracy: 0.8341\n",
      "Epoch 98/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3385 - accuracy: 0.8463\n",
      "Epoch 99/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3506 - accuracy: 0.8313\n",
      "Epoch 100/100\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3535 - accuracy: 0.8463\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.3643 - accuracy: 0.8351\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import SimpleRNN\n",
    "\n",
    "# Build SimpleRNN model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=64, activation='relu', input_shape=(X_train.shape[1], 1), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(SimpleRNN(units=32, activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(SimpleRNN(units=8, activation='relu'))\n",
    "model.add(Dense(units=1,activation='tanh'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping callback\n",
    "# early_stop = EarlyStopping(monitor='loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(X_test,y_test)\n",
    "# print(f'Classification report is: {classification_report(y_pred,y_test)} \\n')\n",
    "# print(f'Confusion matrix is: {confusion_matrix(y_pred,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e16b7514",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"lstm_70\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16488\\51379743.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    236\u001b[0m                     \u001b[1;34mf'Input {input_index} of layer \"{layer_name}\" '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m                     \u001b[1;34m\"is incompatible with the layer: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"lstm_70\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 64)"
     ]
    }
   ],
   "source": [
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=8, activation='relu'))\n",
    "model.add(Dense(units=1, activation='tanh'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping callback\n",
    "# early_stop = EarlyStopping(monitor='loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc97414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
