{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a19e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0687e10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fani\\AppData\\Local\\Temp\\ipykernel_24052\\4035379488.py:5: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data.fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('btc_1d.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02775bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "data.fillna(method='ffill', inplace=True)\n",
    "data.drop(['Date'], axis=1, inplace=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Create sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:(i + seq_length)])\n",
    "        y.append(data[i + seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "sequence_length = 1\n",
    "X, y = create_sequences(scaled_data, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cc00e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 4s 25ms/step - loss: 0.2665 - mae: 0.4443 - val_loss: 0.1863 - val_mae: 0.3674\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.1230 - mae: 0.2841 - val_loss: 0.0691 - val_mae: 0.2104\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0637 - mae: 0.1958 - val_loss: 0.0542 - val_mae: 0.1753\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0560 - mae: 0.1821 - val_loss: 0.0503 - val_mae: 0.1693\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0506 - mae: 0.1722 - val_loss: 0.0459 - val_mae: 0.1603\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0461 - mae: 0.1631 - val_loss: 0.0428 - val_mae: 0.1536\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0435 - mae: 0.1573 - val_loss: 0.0409 - val_mae: 0.1490\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0406 - mae: 0.1508 - val_loss: 0.0386 - val_mae: 0.1441\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0384 - mae: 0.1453 - val_loss: 0.0366 - val_mae: 0.1398\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0377 - mae: 0.1436 - val_loss: 0.0358 - val_mae: 0.1378\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0365 - mae: 0.1406 - val_loss: 0.0341 - val_mae: 0.1344\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0354 - mae: 0.1383 - val_loss: 0.0331 - val_mae: 0.1322\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0342 - mae: 0.1351 - val_loss: 0.0322 - val_mae: 0.1303\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0342 - mae: 0.1351 - val_loss: 0.0319 - val_mae: 0.1307\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0330 - mae: 0.1320 - val_loss: 0.0311 - val_mae: 0.1285\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0324 - mae: 0.1309 - val_loss: 0.0312 - val_mae: 0.1288\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0316 - mae: 0.1287 - val_loss: 0.0304 - val_mae: 0.1268\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0311 - mae: 0.1281 - val_loss: 0.0296 - val_mae: 0.1249\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0313 - mae: 0.1275 - val_loss: 0.0291 - val_mae: 0.1245\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0298 - mae: 0.1245 - val_loss: 0.0287 - val_mae: 0.1230\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0301 - mae: 0.1251 - val_loss: 0.0286 - val_mae: 0.1232\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0293 - mae: 0.1229 - val_loss: 0.0283 - val_mae: 0.1222\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0289 - mae: 0.1217 - val_loss: 0.0279 - val_mae: 0.1214\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0292 - mae: 0.1219 - val_loss: 0.0273 - val_mae: 0.1201\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0282 - mae: 0.1200 - val_loss: 0.0278 - val_mae: 0.1210\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0281 - mae: 0.1198 - val_loss: 0.0272 - val_mae: 0.1190\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0288 - mae: 0.1207 - val_loss: 0.0266 - val_mae: 0.1178\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0278 - mae: 0.1193 - val_loss: 0.0265 - val_mae: 0.1179\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0275 - mae: 0.1179 - val_loss: 0.0263 - val_mae: 0.1168\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0275 - mae: 0.1176 - val_loss: 0.0260 - val_mae: 0.1162\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0271 - mae: 0.1168 - val_loss: 0.0259 - val_mae: 0.1158\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0269 - mae: 0.1159 - val_loss: 0.0253 - val_mae: 0.1142\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0265 - mae: 0.1155 - val_loss: 0.0264 - val_mae: 0.1159\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0263 - mae: 0.1143 - val_loss: 0.0250 - val_mae: 0.1137\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0261 - mae: 0.1137 - val_loss: 0.0249 - val_mae: 0.1132\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0260 - mae: 0.1131 - val_loss: 0.0246 - val_mae: 0.1117\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0265 - mae: 0.1142 - val_loss: 0.0251 - val_mae: 0.1136\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0260 - mae: 0.1135 - val_loss: 0.0247 - val_mae: 0.1123\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0253 - mae: 0.1113 - val_loss: 0.0242 - val_mae: 0.1113\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0254 - mae: 0.1110 - val_loss: 0.0237 - val_mae: 0.1102\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0250 - mae: 0.1109 - val_loss: 0.0237 - val_mae: 0.1101\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0255 - mae: 0.1121 - val_loss: 0.0238 - val_mae: 0.1098\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0250 - mae: 0.1108 - val_loss: 0.0243 - val_mae: 0.1105\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0244 - mae: 0.1088 - val_loss: 0.0237 - val_mae: 0.1095\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0253 - mae: 0.1108 - val_loss: 0.0234 - val_mae: 0.1084\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0245 - mae: 0.1087 - val_loss: 0.0235 - val_mae: 0.1087\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0248 - mae: 0.1093 - val_loss: 0.0239 - val_mae: 0.1087\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0240 - mae: 0.1077 - val_loss: 0.0234 - val_mae: 0.1079\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0246 - mae: 0.1091 - val_loss: 0.0231 - val_mae: 0.1075\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0244 - mae: 0.1084 - val_loss: 0.0230 - val_mae: 0.1083\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0240 - mae: 0.1067 - val_loss: 0.0228 - val_mae: 0.1065\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0239 - mae: 0.1071 - val_loss: 0.0227 - val_mae: 0.1058\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0240 - mae: 0.1071 - val_loss: 0.0231 - val_mae: 0.1067\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0234 - mae: 0.1058 - val_loss: 0.0232 - val_mae: 0.1070\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0237 - mae: 0.1057 - val_loss: 0.0231 - val_mae: 0.1073\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0243 - mae: 0.1078 - val_loss: 0.0229 - val_mae: 0.1066\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0239 - mae: 0.1071 - val_loss: 0.0222 - val_mae: 0.1047\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0237 - mae: 0.1060 - val_loss: 0.0220 - val_mae: 0.1037\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0242 - mae: 0.1069 - val_loss: 0.0221 - val_mae: 0.1044\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0237 - mae: 0.1058 - val_loss: 0.0219 - val_mae: 0.1037\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0234 - mae: 0.1051 - val_loss: 0.0220 - val_mae: 0.1042\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0232 - mae: 0.1044 - val_loss: 0.0219 - val_mae: 0.1030\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0237 - mae: 0.1057 - val_loss: 0.0221 - val_mae: 0.1037\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0235 - mae: 0.1055 - val_loss: 0.0218 - val_mae: 0.1029\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0227 - mae: 0.1029 - val_loss: 0.0217 - val_mae: 0.1025\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0232 - mae: 0.1037 - val_loss: 0.0220 - val_mae: 0.1032\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0232 - mae: 0.1033 - val_loss: 0.0215 - val_mae: 0.1015\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0233 - mae: 0.1046 - val_loss: 0.0215 - val_mae: 0.1021\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0234 - mae: 0.1045 - val_loss: 0.0216 - val_mae: 0.1019\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0228 - mae: 0.1027 - val_loss: 0.0215 - val_mae: 0.1018\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0227 - mae: 0.1025 - val_loss: 0.0211 - val_mae: 0.1004\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0228 - mae: 0.1028 - val_loss: 0.0210 - val_mae: 0.1002\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0228 - mae: 0.1028 - val_loss: 0.0214 - val_mae: 0.1014\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0232 - mae: 0.1041 - val_loss: 0.0211 - val_mae: 0.1003\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0229 - mae: 0.1032 - val_loss: 0.0216 - val_mae: 0.1013\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0229 - mae: 0.1029 - val_loss: 0.0210 - val_mae: 0.1004\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0227 - mae: 0.1026 - val_loss: 0.0212 - val_mae: 0.1005\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0227 - mae: 0.1028 - val_loss: 0.0213 - val_mae: 0.1010\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0224 - mae: 0.1015 - val_loss: 0.0211 - val_mae: 0.1005\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0225 - mae: 0.1016 - val_loss: 0.0215 - val_mae: 0.1019\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0227 - mae: 0.1021 - val_loss: 0.0215 - val_mae: 0.1017\n",
      "Epoch 82/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0230 - mae: 0.1026 - val_loss: 0.0212 - val_mae: 0.1011\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0221 - mae: 0.1003 - val_loss: 0.0212 - val_mae: 0.1001\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0226 - mae: 0.1021 - val_loss: 0.0211 - val_mae: 0.1003\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0225 - mae: 0.1014 - val_loss: 0.0210 - val_mae: 0.0996\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0227 - mae: 0.1024 - val_loss: 0.0211 - val_mae: 0.1010\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0223 - mae: 0.1012 - val_loss: 0.0209 - val_mae: 0.0998\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0223 - mae: 0.1012 - val_loss: 0.0207 - val_mae: 0.0986\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0221 - mae: 0.1004 - val_loss: 0.0210 - val_mae: 0.1002\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0223 - mae: 0.1009 - val_loss: 0.0207 - val_mae: 0.0983\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0218 - mae: 0.0997 - val_loss: 0.0209 - val_mae: 0.0997\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0218 - mae: 0.0998 - val_loss: 0.0208 - val_mae: 0.0988\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0217 - mae: 0.0995 - val_loss: 0.0208 - val_mae: 0.0991\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0223 - mae: 0.1005 - val_loss: 0.0210 - val_mae: 0.0998\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0219 - mae: 0.0995 - val_loss: 0.0207 - val_mae: 0.0982\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0222 - mae: 0.1011 - val_loss: 0.0208 - val_mae: 0.0990\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0220 - mae: 0.1000 - val_loss: 0.0205 - val_mae: 0.0980\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0224 - mae: 0.1006 - val_loss: 0.0206 - val_mae: 0.0978\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0218 - mae: 0.0987 - val_loss: 0.0211 - val_mae: 0.0999\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0219 - mae: 0.0986 - val_loss: 0.0210 - val_mae: 0.0995\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0226 - mae: 0.1085\n",
      "Mean Squared Error: 0.022641124203801155, Mean Absolute Error: 0.1084924042224884\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "split = int(0.7 * len(X))\n",
    "X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=y_train.shape[1]))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stop])\n",
    "\n",
    "# Evaluate model\n",
    "mse, mae = model.evaluate(X_test, y_test)\n",
    "print(f'Mean Squared Error: {mse}, Mean Absolute Error: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9dba1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 4s 33ms/step - loss: 0.3090 - mae: 0.4827 - val_loss: 0.2563 - val_mae: 0.4408\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.2383 - mae: 0.4110 - val_loss: 0.1829 - val_mae: 0.3566\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.1884 - mae: 0.3558 - val_loss: 0.1415 - val_mae: 0.3067\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.1509 - mae: 0.3137 - val_loss: 0.1118 - val_mae: 0.2687\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.1205 - mae: 0.2775 - val_loss: 0.0918 - val_mae: 0.2421\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.1006 - mae: 0.2527 - val_loss: 0.0778 - val_mae: 0.2233\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0872 - mae: 0.2349 - val_loss: 0.0673 - val_mae: 0.2087\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0718 - mae: 0.2117 - val_loss: 0.0576 - val_mae: 0.1916\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0682 - mae: 0.2035 - val_loss: 0.0529 - val_mae: 0.1812\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0611 - mae: 0.1902 - val_loss: 0.0521 - val_mae: 0.1777\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0608 - mae: 0.1894 - val_loss: 0.0489 - val_mae: 0.1723\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0574 - mae: 0.1832 - val_loss: 0.0475 - val_mae: 0.1679\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0564 - mae: 0.1818 - val_loss: 0.0473 - val_mae: 0.1680\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0563 - mae: 0.1824 - val_loss: 0.0466 - val_mae: 0.1656\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0534 - mae: 0.1763 - val_loss: 0.0474 - val_mae: 0.1665\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0533 - mae: 0.1763 - val_loss: 0.0454 - val_mae: 0.1629\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0516 - mae: 0.1728 - val_loss: 0.0455 - val_mae: 0.1628\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0513 - mae: 0.1728 - val_loss: 0.0452 - val_mae: 0.1614\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0490 - mae: 0.1685 - val_loss: 0.0457 - val_mae: 0.1628\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0483 - mae: 0.1663 - val_loss: 0.0446 - val_mae: 0.1608\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0491 - mae: 0.1687 - val_loss: 0.0437 - val_mae: 0.1594\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0457 - mae: 0.1621 - val_loss: 0.0440 - val_mae: 0.1594\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0481 - mae: 0.1658 - val_loss: 0.0436 - val_mae: 0.1592\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0446 - mae: 0.1590 - val_loss: 0.0432 - val_mae: 0.1578\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0448 - mae: 0.1596 - val_loss: 0.0426 - val_mae: 0.1560\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0440 - mae: 0.1585 - val_loss: 0.0428 - val_mae: 0.1566\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0440 - mae: 0.1586 - val_loss: 0.0423 - val_mae: 0.1551\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0439 - mae: 0.1580 - val_loss: 0.0419 - val_mae: 0.1552\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0423 - mae: 0.1543 - val_loss: 0.0421 - val_mae: 0.1557\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0421 - mae: 0.1538 - val_loss: 0.0417 - val_mae: 0.1540\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0421 - mae: 0.1535 - val_loss: 0.0411 - val_mae: 0.1527\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0405 - mae: 0.1488 - val_loss: 0.0421 - val_mae: 0.1551\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0396 - mae: 0.1486 - val_loss: 0.0415 - val_mae: 0.1544\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0399 - mae: 0.1489 - val_loss: 0.0408 - val_mae: 0.1522\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0396 - mae: 0.1475 - val_loss: 0.0403 - val_mae: 0.1519\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0395 - mae: 0.1474 - val_loss: 0.0409 - val_mae: 0.1529\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0383 - mae: 0.1441 - val_loss: 0.0404 - val_mae: 0.1515\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0385 - mae: 0.1445 - val_loss: 0.0404 - val_mae: 0.1512\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0376 - mae: 0.1424 - val_loss: 0.0398 - val_mae: 0.1504\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0375 - mae: 0.1423 - val_loss: 0.0403 - val_mae: 0.1511\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0374 - mae: 0.1417 - val_loss: 0.0401 - val_mae: 0.1510\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0373 - mae: 0.1417 - val_loss: 0.0397 - val_mae: 0.1505\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0366 - mae: 0.1401 - val_loss: 0.0391 - val_mae: 0.1486\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0358 - mae: 0.1387 - val_loss: 0.0396 - val_mae: 0.1497\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0360 - mae: 0.1382 - val_loss: 0.0396 - val_mae: 0.1500\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0354 - mae: 0.1373 - val_loss: 0.0395 - val_mae: 0.1495\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0356 - mae: 0.1372 - val_loss: 0.0393 - val_mae: 0.1489\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0356 - mae: 0.1368 - val_loss: 0.0384 - val_mae: 0.1474\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0350 - mae: 0.1356 - val_loss: 0.0388 - val_mae: 0.1477\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0348 - mae: 0.1346 - val_loss: 0.0387 - val_mae: 0.1474\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0347 - mae: 0.1349 - val_loss: 0.0386 - val_mae: 0.1476\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0348 - mae: 0.1347 - val_loss: 0.0385 - val_mae: 0.1469\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0342 - mae: 0.1338 - val_loss: 0.0379 - val_mae: 0.1454\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0342 - mae: 0.1336 - val_loss: 0.0381 - val_mae: 0.1461\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0338 - mae: 0.1323 - val_loss: 0.0386 - val_mae: 0.1480\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0344 - mae: 0.1333 - val_loss: 0.0386 - val_mae: 0.1471\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0334 - mae: 0.1307 - val_loss: 0.0381 - val_mae: 0.1464\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0333 - mae: 0.1308 - val_loss: 0.0379 - val_mae: 0.1459\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0326 - mae: 0.1291 - val_loss: 0.0377 - val_mae: 0.1454\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0333 - mae: 0.1302 - val_loss: 0.0381 - val_mae: 0.1466\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0342 - mae: 0.1325 - val_loss: 0.0382 - val_mae: 0.1464\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0333 - mae: 0.1310 - val_loss: 0.0377 - val_mae: 0.1454\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0324 - mae: 0.1284 - val_loss: 0.0380 - val_mae: 0.1461\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0337 - mae: 0.1310 - val_loss: 0.0378 - val_mae: 0.1462\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0329 - mae: 0.1299 - val_loss: 0.0374 - val_mae: 0.1447\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0330 - mae: 0.1302 - val_loss: 0.0375 - val_mae: 0.1455\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0323 - mae: 0.1284 - val_loss: 0.0377 - val_mae: 0.1460\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0332 - mae: 0.1295 - val_loss: 0.0377 - val_mae: 0.1454\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0330 - mae: 0.1294 - val_loss: 0.0374 - val_mae: 0.1445\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0321 - mae: 0.1273 - val_loss: 0.0373 - val_mae: 0.1448\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.0322 - mae: 0.1281 - val_loss: 0.0377 - val_mae: 0.1460\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0316 - mae: 0.1266 - val_loss: 0.0377 - val_mae: 0.1458\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0320 - mae: 0.1277 - val_loss: 0.0372 - val_mae: 0.1442\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0316 - mae: 0.1270 - val_loss: 0.0370 - val_mae: 0.1443\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0320 - mae: 0.1273 - val_loss: 0.0373 - val_mae: 0.1445\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0314 - mae: 0.1256 - val_loss: 0.0371 - val_mae: 0.1445\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0318 - mae: 0.1267 - val_loss: 0.0372 - val_mae: 0.1444\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0310 - mae: 0.1250 - val_loss: 0.0373 - val_mae: 0.1443\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0321 - mae: 0.1267 - val_loss: 0.0372 - val_mae: 0.1448\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0319 - mae: 0.1267 - val_loss: 0.0368 - val_mae: 0.1433\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0318 - mae: 0.1266 - val_loss: 0.0371 - val_mae: 0.1446\n",
      "Epoch 82/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0315 - mae: 0.1256 - val_loss: 0.0372 - val_mae: 0.1443\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0310 - mae: 0.1250 - val_loss: 0.0368 - val_mae: 0.1438\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0312 - mae: 0.1248 - val_loss: 0.0369 - val_mae: 0.1436\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0308 - mae: 0.1243 - val_loss: 0.0370 - val_mae: 0.1440\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0313 - mae: 0.1250 - val_loss: 0.0370 - val_mae: 0.1442\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0311 - mae: 0.1250 - val_loss: 0.0370 - val_mae: 0.1442\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0316 - mae: 0.1255 - val_loss: 0.0365 - val_mae: 0.1430\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0309 - mae: 0.1237 - val_loss: 0.0363 - val_mae: 0.1429\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0312 - mae: 0.1257 - val_loss: 0.0364 - val_mae: 0.1432\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0305 - mae: 0.1228 - val_loss: 0.0365 - val_mae: 0.1433\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0306 - mae: 0.1226 - val_loss: 0.0364 - val_mae: 0.1433\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0307 - mae: 0.1237 - val_loss: 0.0365 - val_mae: 0.1433\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0309 - mae: 0.1246 - val_loss: 0.0363 - val_mae: 0.1428\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0301 - mae: 0.1221 - val_loss: 0.0364 - val_mae: 0.1431\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0306 - mae: 0.1235 - val_loss: 0.0362 - val_mae: 0.1432\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0305 - mae: 0.1237 - val_loss: 0.0368 - val_mae: 0.1436\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0305 - mae: 0.1234 - val_loss: 0.0361 - val_mae: 0.1426\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0304 - mae: 0.1221 - val_loss: 0.0360 - val_mae: 0.1418\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0304 - mae: 0.1228 - val_loss: 0.0364 - val_mae: 0.1430\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0407 - mae: 0.1529\n",
      "Mean Squared Error: 0.040689948946237564, Mean Absolute Error: 0.15286538004875183\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import SimpleRNN\n",
    "\n",
    "# Build SimpleRNN model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=32, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(SimpleRNN(units=16, activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(SimpleRNN(units=8, activation='relu'))\n",
    "model.add(Dense(units=y_train.shape[1]))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stop])\n",
    "\n",
    "# Evaluate model\n",
    "mse, mae = model.evaluate(X_test, y_test)\n",
    "print(f'Mean Squared Error: {mse}, Mean Absolute Error: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b04fb187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADX</th>\n",
       "      <th>DI+</th>\n",
       "      <th>DI-</th>\n",
       "      <th>RSI</th>\n",
       "      <th>AROON UP</th>\n",
       "      <th>AROON DOWN</th>\n",
       "      <th>BOP</th>\n",
       "      <th>CCI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal</th>\n",
       "      <th>...</th>\n",
       "      <th>K%</th>\n",
       "      <th>D%</th>\n",
       "      <th>rsi_K%</th>\n",
       "      <th>rsi_D%</th>\n",
       "      <th>WillR%</th>\n",
       "      <th>Trix</th>\n",
       "      <th>atr</th>\n",
       "      <th>obv</th>\n",
       "      <th>Pvt</th>\n",
       "      <th>fractal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.150019</td>\n",
       "      <td>26.443189</td>\n",
       "      <td>27.860541</td>\n",
       "      <td>50.593983</td>\n",
       "      <td>71.428571</td>\n",
       "      <td>21.428571</td>\n",
       "      <td>-0.530185</td>\n",
       "      <td>-41.179946</td>\n",
       "      <td>0.434641</td>\n",
       "      <td>0.463968</td>\n",
       "      <td>...</td>\n",
       "      <td>44.102583</td>\n",
       "      <td>52.600875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.331274</td>\n",
       "      <td>-74.208097</td>\n",
       "      <td>0.189917</td>\n",
       "      <td>1.897965</td>\n",
       "      <td>-512846000</td>\n",
       "      <td>-4.876349e+08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.254307</td>\n",
       "      <td>25.350284</td>\n",
       "      <td>26.709056</td>\n",
       "      <td>50.462471</td>\n",
       "      <td>64.285714</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-43.482859</td>\n",
       "      <td>0.361163</td>\n",
       "      <td>0.443407</td>\n",
       "      <td>...</td>\n",
       "      <td>33.816045</td>\n",
       "      <td>43.831101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-74.751061</td>\n",
       "      <td>0.185472</td>\n",
       "      <td>1.838814</td>\n",
       "      <td>-591443600</td>\n",
       "      <td>-4.903250e+08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.429050</td>\n",
       "      <td>23.145847</td>\n",
       "      <td>32.426892</td>\n",
       "      <td>42.576147</td>\n",
       "      <td>57.142857</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-0.984331</td>\n",
       "      <td>-146.361977</td>\n",
       "      <td>0.220305</td>\n",
       "      <td>0.398786</td>\n",
       "      <td>...</td>\n",
       "      <td>17.040874</td>\n",
       "      <td>31.653167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-99.918221</td>\n",
       "      <td>0.176421</td>\n",
       "      <td>1.913036</td>\n",
       "      <td>-739663200</td>\n",
       "      <td>-8.261113e+08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.193591</td>\n",
       "      <td>21.118462</td>\n",
       "      <td>35.297196</td>\n",
       "      <td>38.614584</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-0.281862</td>\n",
       "      <td>-209.781751</td>\n",
       "      <td>0.059173</td>\n",
       "      <td>0.330864</td>\n",
       "      <td>...</td>\n",
       "      <td>9.002857</td>\n",
       "      <td>19.953259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-98.322147</td>\n",
       "      <td>0.162527</td>\n",
       "      <td>1.974446</td>\n",
       "      <td>-905626400</td>\n",
       "      <td>-1.060613e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.601016</td>\n",
       "      <td>18.937984</td>\n",
       "      <td>39.241023</td>\n",
       "      <td>33.233998</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-0.692771</td>\n",
       "      <td>-254.075441</td>\n",
       "      <td>-0.145721</td>\n",
       "      <td>0.235547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586544</td>\n",
       "      <td>8.876758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.142781</td>\n",
       "      <td>2.092539</td>\n",
       "      <td>-1069741600</td>\n",
       "      <td>-1.440649e+09</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ADX        DI+        DI-        RSI   AROON UP  AROON DOWN  \\\n",
       "0  15.150019  26.443189  27.860541  50.593983  71.428571   21.428571   \n",
       "1  14.254307  25.350284  26.709056  50.462471  64.285714   14.285714   \n",
       "2  14.429050  23.145847  32.426892  42.576147  57.142857  100.000000   \n",
       "3  15.193591  21.118462  35.297196  38.614584  50.000000  100.000000   \n",
       "4  16.601016  18.937984  39.241023  33.233998  42.857143  100.000000   \n",
       "\n",
       "        BOP         CCI      MACD    Signal  ...         K%         D%  \\\n",
       "0 -0.530185  -41.179946  0.434641  0.463968  ...  44.102583  52.600875   \n",
       "1  0.000000  -43.482859  0.361163  0.443407  ...  33.816045  43.831101   \n",
       "2 -0.984331 -146.361977  0.220305  0.398786  ...  17.040874  31.653167   \n",
       "3 -0.281862 -209.781751  0.059173  0.330864  ...   9.002857  19.953259   \n",
       "4 -0.692771 -254.075441 -0.145721  0.235547  ...   0.586544   8.876758   \n",
       "\n",
       "   rsi_K%    rsi_D%      WillR%      Trix       atr         obv           Pvt  \\\n",
       "0     0.0  3.331274  -74.208097  0.189917  1.897965  -512846000 -4.876349e+08   \n",
       "1     0.0  0.000000  -74.751061  0.185472  1.838814  -591443600 -4.903250e+08   \n",
       "2     0.0  0.000000  -99.918221  0.176421  1.913036  -739663200 -8.261113e+08   \n",
       "3     0.0  0.000000  -98.322147  0.162527  1.974446  -905626400 -1.060613e+09   \n",
       "4     0.0  0.000000 -100.000000  0.142781  2.092539 -1069741600 -1.440649e+09   \n",
       "\n",
       "   fractal  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4       -1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c92f922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4485.39</td>\n",
       "      <td>4200.74</td>\n",
       "      <td>4285.08</td>\n",
       "      <td>795.150377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>4285.08</td>\n",
       "      <td>4371.52</td>\n",
       "      <td>3938.77</td>\n",
       "      <td>4108.37</td>\n",
       "      <td>1199.888264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>4108.37</td>\n",
       "      <td>4184.69</td>\n",
       "      <td>3850.00</td>\n",
       "      <td>4139.98</td>\n",
       "      <td>381.309763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>4120.98</td>\n",
       "      <td>4211.08</td>\n",
       "      <td>4032.62</td>\n",
       "      <td>4086.29</td>\n",
       "      <td>467.083022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-21</td>\n",
       "      <td>4069.13</td>\n",
       "      <td>4119.62</td>\n",
       "      <td>3911.79</td>\n",
       "      <td>4016.00</td>\n",
       "      <td>691.743060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp     open     high      low    close       volume\n",
       "0  2017-08-17  4261.48  4485.39  4200.74  4285.08   795.150377\n",
       "1  2017-08-18  4285.08  4371.52  3938.77  4108.37  1199.888264\n",
       "2  2017-08-19  4108.37  4184.69  3850.00  4139.98   381.309763\n",
       "3  2017-08-20  4120.98  4211.08  4032.62  4086.29   467.083022\n",
       "4  2017-08-21  4069.13  4119.62  3911.79  4016.00   691.743060"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('btc_1d.csv')\n",
    "\n",
    "# Preprocessing\n",
    "# data.fillna(method='ffill', inplace=True)\n",
    "# data.drop(['Date'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e38e7891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.10791075, 0.3986611 , 0.53337988, ..., 0.21857928,\n",
       "         0.46661161, 0.5       ]],\n",
       "\n",
       "       [[0.08955496, 0.37381075, 0.50519512, ..., 0.20455232,\n",
       "         0.46646589, 0.5       ]],\n",
       "\n",
       "       [[0.09313597, 0.32368651, 0.64514994, ..., 0.17810023,\n",
       "         0.44827604, 0.5       ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.09565967, 0.25503701, 0.65135253, ..., 0.6572339 ,\n",
       "         0.83120254, 0.5       ]],\n",
       "\n",
       "       [[0.11884967, 0.21688114, 0.69737667, ..., 0.64198609,\n",
       "         0.81700058, 0.        ]],\n",
       "\n",
       "       [[0.14038325, 0.18679615, 0.63670669, ..., 0.65549659,\n",
       "         0.82861622, 0.5       ]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "993616bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1207 entries, 0 to 1206\n",
      "Data columns (total 23 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   ADX         1207 non-null   float64\n",
      " 1   DI+         1207 non-null   float64\n",
      " 2   DI-         1207 non-null   float64\n",
      " 3   RSI         1207 non-null   float64\n",
      " 4   AROON UP    1207 non-null   float64\n",
      " 5   AROON DOWN  1207 non-null   float64\n",
      " 6   BOP         1207 non-null   float64\n",
      " 7   CCI         1207 non-null   float64\n",
      " 8   MACD        1207 non-null   float64\n",
      " 9   Signal      1207 non-null   float64\n",
      " 10  MFI         1207 non-null   float64\n",
      " 11  Mom         1207 non-null   float64\n",
      " 12  ROC         1207 non-null   float64\n",
      " 13  K%          1207 non-null   float64\n",
      " 14  D%          1207 non-null   float64\n",
      " 15  rsi_K%      1207 non-null   float64\n",
      " 16  rsi_D%      1207 non-null   float64\n",
      " 17  WillR%      1207 non-null   float64\n",
      " 18  Trix        1207 non-null   float64\n",
      " 19  atr         1207 non-null   float64\n",
      " 20  obv         1207 non-null   int64  \n",
      " 21  Pvt         1207 non-null   float64\n",
      " 22  fractal     1207 non-null   int64  \n",
      "dtypes: float64(21), int64(2)\n",
      "memory usage: 217.0 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "704a76fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1206, 1, 23)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faa2725",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
